{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, 'C:/Users/Nguyễn Hoài Nam/OneDrive/CDIO4')\n",
    "import pose_media as pm\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import cv2\n",
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "from PyQt5.QtWidgets import QFileDialog\n",
    "from PyQt5.QtGui import QImage,QPixmap,QBitmap\n",
    "from PyQt5.QtWidgets import  QWidget, QLabel, QApplication\n",
    "from PyQt5.QtCore import QThread, Qt, pyqtSignal, pyqtSlot\n",
    "from PyQt5.QtGui import QImage, QPixmap\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mUi_Dialog\u001B[39;00m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[0;32m      2\u001B[0m     threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.6\u001B[39m\n\u001B[0;32m      3\u001B[0m     actions \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwalking\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboxing\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandwaving\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m, in \u001B[0;36mUi_Dialog\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mUi_Dialog\u001B[39;00m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[0;32m      2\u001B[0m     threshold \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.6\u001B[39m\n\u001B[1;32m----> 3\u001B[0m     actions \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwalking\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboxing\u001B[39m\u001B[38;5;124m\"\u001B[39m,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhandwaving\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m      4\u001B[0m     pTime \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      5\u001B[0m     cTime \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class Ui_Dialog(object):\n",
    "    threshold = 0.6\n",
    "    actions = np.array([\"walking\",\"boxing\",\"handwaving\"])\n",
    "    pTime = 0\n",
    "    cTime = 0\n",
    "    def setupUi(self, Dialog):\n",
    "        Dialog.setObjectName(\"Dialog\")\n",
    "        Dialog.resize(838, 616)\n",
    "        self.widget = QtWidgets.QWidget(Dialog)\n",
    "        self.widget.setGeometry(QtCore.QRect(42, 32, 781, 571))\n",
    "        self.widget.setObjectName(\"widget\")\n",
    "        self.gridLayout = QtWidgets.QGridLayout(self.widget)\n",
    "        self.gridLayout.setContentsMargins(0, 0, 0, 0)\n",
    "        self.gridLayout.setObjectName(\"gridLayout\")\n",
    "        self.video_click = QtWidgets.QPushButton(self.widget,clicked = lambda : self.video_cap())\n",
    "        self.video_click.setObjectName(\"video_click\")\n",
    "        self.gridLayout.addWidget(self.video_click, 2, 1, 1, 1)\n",
    "        self.label_load_action = QtWidgets.QLabel(self.widget)\n",
    "        self.label_load_action.setObjectName(\"label_load_action\")\n",
    "        self.gridLayout.addWidget(self.label_load_action, 0, 2, 1, 1)\n",
    "        self.label_FPS = QtWidgets.QLabel(self.widget)\n",
    "        self.label_FPS.setObjectName(\"label_FPS\")\n",
    "        self.gridLayout.addWidget(self.label_FPS, 1, 2, 1, 1)\n",
    "        self.webcam_click = QtWidgets.QPushButton(self.widget,clicked = lambda :self.web_cam())\n",
    "        self.webcam_click.setObjectName(\"webcam_click\")\n",
    "        self.gridLayout.addWidget(self.webcam_click, 2, 0, 1, 1)\n",
    "        self.label_load_video = QtWidgets.QLabel(self.widget)\n",
    "        self.label_load_video.setObjectName(\"label_load_video\")\n",
    "        self.gridLayout.addWidget(self.label_load_video, 0, 0, 2, 2)\n",
    "        \n",
    "        \n",
    "        self.pose = pm.mediapipe_pose()\n",
    "        self.pt = self.pose.mp_holistic.Holistic()\n",
    "        self.new_model = torch.load('model.pth')\n",
    "        self.new_model.eval()\n",
    "        \n",
    "        self.sequence = []\n",
    "        self.sentence = []\n",
    "        \n",
    "        \n",
    "        self.retranslateUi(Dialog)\n",
    "        QtCore.QMetaObject.connectSlotsByName(Dialog)\n",
    "    \n",
    "    \n",
    "    def web_cam(self):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        while cap.isOpened():\n",
    "            ret,frame = cap.read()\n",
    "            try:\n",
    "                frame,results = self.pose.mediapipe_detection(frame,self.pt)\n",
    "            except:\n",
    "                pass\n",
    "            self.pose.draw_styled_landmarks(frame,results)\n",
    "            keypoints = self.pose.extract_keypoints(results)\n",
    "            # frame.shape摄像头捕获的图像480x640x3\n",
    "            # keypoints关键点132维度\n",
    "            self.sequence.append(keypoints)\n",
    "            self.sequence = self.sequence[-30:]\n",
    "            # print(np.expand_dims(self.sequence, axis=0).shape)\n",
    "            if len(self.sequence) == 30:\n",
    "                inputs = torch.from_numpy(np.expand_dims(self.sequence, axis=0)[0]).unsqueeze(0).to(torch.float32)\n",
    "                inputs = inputs.repeat(2,1,1)\n",
    "                res = self.new_model(inputs)[0]\n",
    "                res = res.detach().numpy()\n",
    "                if res[np.argmax(res)] > self.threshold:\n",
    "                    if len(self.sentence) > 0:\n",
    "                        if self.actions[np.argmax(res)] != self.sentence[-1]:\n",
    "                            self.sentence.append(self.actions[np.argmax(res)])\n",
    "                    else:\n",
    "                        self.sentence.append(self.actions[np.argmax(res)])\n",
    "                if len(self.sentence) > 1: \n",
    "                    self.sentence = self.sentence[-1:]\n",
    "            self.label_load_action.setText(' '.join(self.sentence))\n",
    "            self.cTime = time.time()\n",
    "            fps = 1 / (self.cTime - self.pTime)\n",
    "            self.pTime = self.cTime\n",
    "            self.label_FPS.setText(\"FPS: \" +str(int(fps)))\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image = QImage(frame.data, frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)\n",
    "            convertToQtFormat = QtGui.QPixmap.fromImage(image)\n",
    "            pixmap = QPixmap(convertToQtFormat)\n",
    "            resizeImage = pixmap.scaled(640, 480, QtCore.Qt.KeepAspectRatio)\n",
    "            QApplication.processEvents()\n",
    "            self.label_load_video.setPixmap(resizeImage)\n",
    "            \n",
    "    def video_cap(self):\n",
    "        path = QtWidgets.QFileDialog.getOpenFileName()[0]\n",
    "        if path:\n",
    "            cap = cv2.VideoCapture(path)\n",
    "            while cap.isOpened():\n",
    "                ret,frame = cap.read()\n",
    "                if len(frame) == 0: break\n",
    "                try:\n",
    "                    frame,results = self.pose.mediapipe_detection(frame,self.pt)\n",
    "                except:\n",
    "                    pass\n",
    "                self.pose.draw_styled_landmarks(frame,results)\n",
    "                keypoints = self.pose.extract_keypoints(results)\n",
    "                self.sequence.append(keypoints)\n",
    "                self.sequence = self.sequence[-30:]\n",
    "                if len(self.sequence) == 30:\n",
    "                    inputs = torch.from_numpy(np.expand_dims(self.sequence, axis=0)[0]).unsqueeze(0).to(torch.float32)\n",
    "                    inputs = inputs.repeat(2,1,1)\n",
    "                    res = self.new_model(inputs)[0]\n",
    "                    res = res.detach().numpy()\n",
    "                    if res[np.argmax(res)] > self.threshold:\n",
    "                        if len(self.sentence) > 0:\n",
    "                            if self.actions[np.argmax(res)] != self.sentence[-1]:\n",
    "                                self.sentence.append(self.actions[np.argmax(res)])\n",
    "                        else:\n",
    "                            self.sentence.append(self.actions[np.argmax(res)])\n",
    "                    if len(self.sentence) > 1: \n",
    "                        self.sentence = self.sentence[-1:]\n",
    "                print(self.sentence)\n",
    "                self.label_load_action.setText(' '.join(self.sentence))\n",
    "                self.cTime = time.time()\n",
    "                fps = 1 / (self.cTime - self.pTime)\n",
    "                self.pTime = self.cTime\n",
    "                self.label_FPS.setText(\"FPS: \" +str(int(fps)))\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image = QImage(frame.data, frame.shape[1],frame.shape[0],frame.strides[0],QImage.Format_RGB888)\n",
    "                convertToQtFormat = QtGui.QPixmap.fromImage(image)\n",
    "                pixmap = QPixmap(convertToQtFormat)\n",
    "                resizeImage = pixmap.scaled(640, 480, QtCore.Qt.KeepAspectRatio)\n",
    "                QApplication.processEvents()\n",
    "                self.label_load_video.setPixmap(resizeImage)\n",
    "            \n",
    "    \n",
    "    def retranslateUi(self, Dialog):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        Dialog.setWindowTitle(_translate(\"Dialog\", \"Dialog\"))\n",
    "        self.video_click.setText(_translate(\"Dialog\", \"Video\"))\n",
    "        self.label_load_action.setText(_translate(\"Dialog\", \"TextLabel\"))\n",
    "        self.label_FPS.setText(_translate(\"Dialog\", \"TextLabel\"))\n",
    "        self.webcam_click.setText(_translate(\"Dialog\", \"Webcam\"))\n",
    "        self.label_load_video.setText(_translate(\"Dialog\", \"TextLabel\"))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    Dialog = QtWidgets.QDialog()\n",
    "    ui = Ui_Dialog()\n",
    "    ui.setupUi(Dialog)\n",
    "    Dialog.show()\n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}